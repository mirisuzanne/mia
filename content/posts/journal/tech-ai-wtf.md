---
draft: true
title: Tech continues to be political
sub: And the politics aren't looking great
date: 2025-02-13
summary: |
  Being "in tech" in 2025 is depressing,
  and if I'm going to stick around,
  I need to remember why I'm here.
---

For years we've been saying that
_tech is political_,
and that _tech is not neutral_.
But I don't feel like we're communicating
the full intent of that adage.
It's not just a warning about bad Apples (or Palantirs)
who might use code to dabble in evil extracurriculars.
More essential to me is the understanding
that _technologies often
[carry an ideology inside them](https://benmyers.dev/blog/spotless-giraffe/)_ --
some more literally than others.
Tools tend to exist between us and a goal,
and the shape of the tool
tells us something about how to proceed,
and what outcomes are desirable.
Tech _enacts_ and _shapes_ our world,
our lives, and our politics.

Guns are (in fact) _designed to help people kill people_.

Maybe we should consider the beliefs and assumptions
that have been built into a technology
before we embrace it?
But we often prefer to treat each new toy
as as an abstract and unmotivated _opportunity_.
If only the _good people like ourselves_
would get involved early,
we can surely teach everyone else to use it ethically!

Once we've established some useful norms --
a 'best practice' or two --
I can't imagine anyone
[_crowd violently storms the capitol_].

Every tool is a hammer,
and it's up to us
to determine _individually_
what looks like a nail.
There is no system, no society,
no marketing department, no regulation.
Each of us is an island of isolated ~~trolly conductors~~
_hammer enthusiasts_.

## Meanwhile, back at the hammer factory…

The AI projects currently mid-hype
are being driven by billionaires and VCs
with companies explicitly
pursuing surveillance, exploitation, and weaponry.
They all fired their ethics teams
at the start of the cycle,
and diverted our attention
to a long-term sci-fi narrative
about the coming age of machines --
a "General Intelligence" that will soon
"surpasses" human ability.

_Be it god or demon,
only the high priests of venture capital
can summon and tame such a powerful being --
for the good of humanity!
It will only cost you all your labor,
and the most massive fundraising ever seen._

What does that mean?
Hand-waving eugenics.
We don't know what it means to be intelligent,
let alone how one intelligence would "surpass" another.
Unless you believe the race science
that these same CEO's seem to be obsessed with.
Now they are eager to jump on board
an authoritarian movement
_that wants to exterminate trans people_,
fire black people,
and deport our immigrant colleagues.

Surely this has nothing to do with their products, though.

## But her use-cases

I know that 'AI' _broadly_ has a long history,
with 'language models' and 'neural nets'
developing real use-cases in science and other fields.
I'm not new here.
But this background level of validity-by-association
is used to prop up some absolute garbage.
But the chatSlop we're drowning in now
is clearly designed for a different purpose.

_Haven't you heard?
They're building a digital god
who will lead us to salvation,
uploaded into the virgo supercluster
where we can expand the light of
[exponential profit](https://bengrosser.com/projects/andreessens-techno-optimist-manifesto-as-redaction-poetry//)
throughout the cosmos!_

This is the actual narrative of several AI CEOs,
despite being easy to dismiss
as hyperbolic nonsense.
Why won't I focus on the actual use-cases?

_Why won't you focus
on the actual documented harms?
Somehow there is always room for people
to dismiss concerns as "overblown and unfounded"
past the first attempted coup,
and well into an authoritarian power grab._

But the bigger issue is that
they don't have to be _successful_ to be _dangerous_.
Because along the way,
they get to steel our work and sell it back to us,
lower our wages, de-skill our field,
bury us in slop, and mire us in algorithmic bureaucracy.
If the long-term space god thing doesn't work out,
at least they can make a profit in the short-term.

The beliefs of these CEOs aren't incidental
to the AI product they're selling us.
These are not tools designed for us to _benefit from_,
but tools designed to _exploit us_.
To poison our access to jobs,
and our access to information at the same time.

I said on social media
that people _believe_ what chatbots tell them,
and I was laughed at.
No one would _trust_ a chatbot, silly!
That same day,
several different friends and colleagues
quoted the output of an 'AI' to me,
in unrelated situations,
all as though quoting reliable facts.

Meanwhile,
a few companies run by billionaires
now control much of the information
that people see --
"summarized" without sources.
Meanwhile,
there's an oligarchy taking power in the US.
Meanwhile,
Grok's entire purpose is to be 'anti-woke',
_[ChatGPT’s Political Views Are Shifting Right, a New Analysis Finds](https://gizmodo.com/chatgpts-political-views-are-shifting-right-a-new-analysis-finds-2000562328)_,
and Anthropic is partnering with Palantir.

Seems chill.
I bet 'agents' are cool.

_Wouldn't want to eat a shrimp cocktail in the rain._

## Tech workers seem to like tech actually

[There's a meme](https://knowyourmeme.com/photos/2069350-twitter-x)
that goes around
about the attitudes of _tech enthusiasts_
vs _tech workers_…

> Tech enthusiasts: My entire house is smart.
>
> Tech workers: The only piece of technology
> in my house is a printer
> and I keep a gun next to it
> so I can shoot it
> if it makes a noise I don't recognize.

I can relate to that sentiment,
but many in our community seem _unfazed_
or even _excited_ about 'AI' and 'Agents'
and 'codegen' and all the rest of it.
As far as I can tell,
most of our industry is still on board with the project,
even when booing the CEOs and changing corporate politics.
There are certainly many of us
raising alarms or expressing frustration, but --
based on every conference I've attended over the last year --
I can absolutely say we're a fringe minority.

And it's wearing me out.
I don't know how to participate
in a community that so eagerly brushes aside
the active and _intentional_/_foundational_ harms of a technology.
In return for what? Faster copypasta?
Automation tools being rebranded as an "agentic" web?
Assurance that we won't be _left behind_?

_This is your opportunity
to get in at the ground floor!
Don't miss your chance!_

I don't know how to attend conferences
full of gushing talks about the tools
that were _designed to negate me_.
I don't have any interest in trying to
reverse-engineer use-cases for it,
or improve the flaws to make it "better",
or help sell it by bending it to new uses.

When eugenics-obsessed billionaires
try to sell me a new toy,
I don't ask how many keystrokes it will save me at work.
If I wanted slop code, I wouldn't be a developer.
It's impossible for me to discuss the _utility_ of a thing
when I fundamentally disagree with the _purpose_ of it.

I don't want any of this.
I don't care if it works, I hate what it's _for_.
I don't need _an agent_,
I want to _maintain my own agency_.

## I don't know

Every time I log on
I feel like I'm being gaslit --
asked to train my shitty replacement,
and then step aside.
The future is _not women_,
I'm learning now.
You can be sued in the US
for intentionally hiring women.
The future is actually _inhuman word synthesizers_.

Oops, I fell for the _genders_
and their sneaky _ideology_!
No I'm a crime!
Haha, oops!

Work is already harder to find,
and companies mostly want help
slopping more slop into the slop machine.
_Because it will help users_, you ask?
Of course not!
But everyone has slop-on-tap,
and needs to do something with it!

[Money, gain, profit!](https://business-business.business/)

What are we doing here?
What am I doing here?
How do I stay engaged in this field,
and keep paying my bills,
without feeling like a constant outsider?
I know I'm not the only one feeling this way,
but the layering of constant betrayals add up,
and it feels so isolating.

## It's probably good to get this clarity

"Tech" was always a vague and hand-waving field --
a way to side-step regulations
while starting an unlicensed taxi company (for example).

But I'm here for the web,
a weird little project
designed for sharing research between scientists.
And I still think the web could be pretty cool, actually,
if it wasn't so trapped in the clutches of tech.
If we can focus on
[the bits that make it special](https://tweets.miriamsuzanne.com/1198717316269084672/) --
the bits that make it unwieldy for capitalism:

> Large companies find HTML & CSS frustrating “at scale”
> because the web is
> a fundamentally anti-capitalist mashup art experiment,
> designed to give consumers all the power.

What are we going to build now --
those of us who still care about
diversity, equity, inclusion, accessibility,
and giving consumers the power?
Can we still put our HTML & CSS to good use?
Can we get back to building a web
where people have _agency_?

Where are you looking to put your energy next?
